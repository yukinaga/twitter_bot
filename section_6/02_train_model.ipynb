{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_train_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOj5XAJyJlzvbd2SZpIc68C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yukinaga/twitter_bot/blob/master/section_6/02_train_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzAWLQ2a3io8"
      },
      "source": [
        "# モデルの訓練\n",
        "対話文の生成するためのモデルを訓練し、保存します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbeonHALP8fU"
      },
      "source": [
        "## ライブラリのインストール\n",
        "分かち書きのためにjanomeを、テキストデータの前処理のためにtorchtextをインストールします。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUm6Vi2wQBfa"
      },
      "source": [
        "!pip install janome==0.4.1\n",
        "!pip install torchvision==0.7.0\n",
        "!pip install torchtext==0.7.0\n",
        "!pip install torch==1.6.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcHOX9LyZc2g"
      },
      "source": [
        "## Google ドライブとの連携  \n",
        "以下のコードを実行し、認証コードを使用してGoogle ドライブをマウントします。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7h7BA67Ed5wT"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zliYGLC5g0h2"
      },
      "source": [
        "## データセットの読み込み\n",
        "保存されている対話文のデータセットを読み込みます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylgqmSkuCvIQ"
      },
      "source": [
        "import torch\n",
        "import torchtext\n",
        "import dill\n",
        "\n",
        "path = \"/content/drive/My Drive/live_ai_data/\"  # 保存場所を指定\n",
        "\n",
        "train_examples = torch.load(path+\"train_examples.pkl\", pickle_module=dill)\n",
        "test_examples = torch.load(path+\"test_examples.pkl\", pickle_module=dill)\n",
        "\n",
        "input_field = torch.load(path+\"input_field.pkl\", pickle_module=dill)\n",
        "reply_field = torch.load(path+\"reply_field.pkl\", pickle_module=dill)\n",
        "\n",
        "train_data = torchtext.data.Dataset(train_examples, [(\"inp_text\", input_field), (\"rep_text\", reply_field)])\n",
        "test_data = torchtext.data.Dataset(test_examples, [(\"inp_text\", input_field), (\"rep_text\", reply_field)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiohzweSnFYZ"
      },
      "source": [
        "## Iteratorの設定\n",
        "バッチごとに学習を行うために、Iteratorを設定します。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sMWHKzjTZkZ"
      },
      "source": [
        "# Iteratorの設定\n",
        "batch_size = 32\n",
        "\n",
        "train_iterator = torchtext.data.Iterator(\n",
        "    train_data,\n",
        "    batch_size=batch_size, \n",
        "    train=True  # シャッフルして取り出す\n",
        ")\n",
        "\n",
        "test_iterator = torchtext.data.Iterator(\n",
        "    test_data,\n",
        "    batch_size=batch_size, \n",
        "    train=False,\n",
        "    sort=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMR9rJHpEaK8"
      },
      "source": [
        "ミニバッチを取り出して、内容を表示します。  \n",
        "ミニバッチには、単語をインデックスに置き換えた文章が格納されます。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_NFDwZopAbr"
      },
      "source": [
        "batch = next(iter(train_iterator))  # ミニバッチを取り出す\n",
        "print(batch.inp_text.size())  # ミニバッチにおける入力のサイズ\n",
        "print(batch.inp_text[0])  # 最初の要素\n",
        "print(batch.rep_text.size())  # ミニバッチにおける応答のサイズ\n",
        "print(batch.rep_text[0])  # 最初の要素"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4L4JUIxfiXIy"
      },
      "source": [
        "## Encoderのクラス\n",
        "Encoderをクラスとして実装します。  \n",
        "RNN部分にはGRUを使用しますが、双方向に情報が流れるBidirectional RNNを設定可能にします。  \n",
        "Bidirectional RNNが設定されている場合、Encoderの出力と隠れ層の値は双方向の時間の値を足したものになります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qj85SCNAmzGC"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, n_h, n_vocab, n_emb, num_layers=1, bidirectional=False, dropout=0.0):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.n_h = n_h\n",
        "        self.num_layers = num_layers\n",
        "        self.bidirectional = bidirectional\n",
        "        self.dropout = dropout  # ドロップアウト層\n",
        "\n",
        "        # 埋め込み層\n",
        "        self.embedding = nn.Embedding(n_vocab, n_emb)\n",
        "        self.embedding_dropout = nn.Dropout(self.dropout)\n",
        "\n",
        "        self.gru = nn.GRU(  # GRU層\n",
        "            input_size=n_emb,  # 入力サイズ\n",
        "            hidden_size=n_h,  # ニューロン数\n",
        "            batch_first=True,  # 入力を (バッチサイズ, 時系列の数, 入力の数) にする\n",
        "            num_layers=num_layers,  # RNN層の数（層を重ねることも可能）\n",
        "            bidirectional=bidirectional,  # Bidrectional RNN\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 文章の長さを取得\n",
        "        idx_pad = input_field.vocab.stoi[\"<pad>\"]\n",
        "        sentence_lengths = x.size()[1] - (x == idx_pad).sum(dim=1)\n",
        "\n",
        "        y = self.embedding(x)  # 単語をベクトルに変換\n",
        "        y = self.embedding_dropout(y)\n",
        "        y = nn.utils.rnn.pack_padded_sequence(  # 入力のパッキング\n",
        "            y,\n",
        "            sentence_lengths,\n",
        "            batch_first=True,\n",
        "            enforce_sorted=False\n",
        "            )\n",
        "        y, h = self.gru(y)\n",
        "\n",
        "        y, _ = nn.utils.rnn.pad_packed_sequence(y, batch_first=True)  # テンソルに戻す\n",
        "        if self.bidirectional:  # 双方向の値を足し合わせる\n",
        "            y = y[:, :, :self.n_h] + y[:, :, self.n_h:]\n",
        "            h = h[:self.num_layers] + h[self.num_layers:]\n",
        "        return y, h"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYCATQ-NpexE"
      },
      "source": [
        "## Decoderのクラス\n",
        "Decoderをクラスとして実装します。  \n",
        "RNN部分にはGRUを使用します。  \n",
        "GRU層の出力は、全結合層を経てDecoderの出力となります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4_k1Lnypm9v"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, n_h, n_out, n_vocab, n_emb, num_layers=1, dropout=0.0):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.n_h = n_h\n",
        "        self.n_out = n_out\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout = dropout\n",
        "\n",
        "        # 埋め込み層\n",
        "        self.embedding = nn.Embedding(n_vocab, n_emb)\n",
        "        self.embedding_dropout = nn.Dropout(self.dropout)  # ドロップアウト層\n",
        "\n",
        "        self.gru = nn.GRU(  # GRU層\n",
        "            input_size=n_emb,  # 入力サイズ\n",
        "            hidden_size=n_h,  # ニューロン数\n",
        "            batch_first=True,  # 入力を (バッチサイズ, 時系列の数, 入力の数) にする\n",
        "            num_layers=num_layers,  # RNN層の数（層を重ねることも可能）\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear(n_h*2, self.n_out)  # コンテキストベクトルが合流するので2倍のサイズ\n",
        "                \n",
        "    def forward(self, x, h_encoder, y_encoder):\n",
        "        y = self.embedding(x)  # 単語をベクトルに変換\n",
        "        y = self.embedding_dropout(y)\n",
        "        y, h = self.gru(y, h_encoder)\n",
        "\n",
        "        # ----- Attension -----\n",
        "        y_tr = torch.transpose(y, 1, 2)  # 次元1と次元2を入れ替える\n",
        "        ed_mat = torch.bmm(y_encoder, y_tr)  # バッチごとに行列積\n",
        "        attn_weight = F.softmax(ed_mat, dim=1)  # attension weightの計算\n",
        "        attn_weight_tr = torch.transpose(attn_weight, 1, 2)  # 次元1と次元2を入れ替える\n",
        "        context = torch.bmm(attn_weight_tr, y_encoder)  # コンテキストベクトルの計算\n",
        "        y = torch.cat([y, context], dim=2)  # 出力とコンテキストベクトルの合流\n",
        "\n",
        "        y = self.fc(y)\n",
        "        y = F.softmax(y, dim=2)\n",
        "        \n",
        "        return y, h"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iz1mobSD4J_K"
      },
      "source": [
        "## Seq2Seqのクラス\n",
        "Seq2Seqを構築します。  \n",
        "`is_gpu`が`True`であれば、GPU対応を行います。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaP3V80wwF_b"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, is_gpu=True):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.is_gpu = is_gpu\n",
        "        if self.is_gpu:\n",
        "            self.encoder.cuda()\n",
        "            self.decoder.cuda()\n",
        "        \n",
        "    def forward(self, x_encoder, x_decoder):  # 訓練に使用\n",
        "        if self.is_gpu:\n",
        "            x_encoder, x_decoder = x_encoder.cuda(), x_decoder.cuda()\n",
        "\n",
        "        batch_size = x_decoder.shape[0]\n",
        "        n_time = x_decoder.shape[1]\n",
        "        y_encoder, h = self.encoder(x_encoder)\n",
        "\n",
        "        y_decoder = torch.zeros(batch_size, n_time, self.decoder.n_out)\n",
        "        if self.is_gpu:\n",
        "            y_decoder = y_decoder.cuda()\n",
        "\n",
        "        for t in range(0, n_time):\n",
        "            x = x_decoder[:, t:t+1]  # Decoderの入力を使用\n",
        "            y, h= self.decoder(x, h, y_encoder)\n",
        "            y_decoder[:, t:t+1, :] = y\n",
        "        return y_decoder\n",
        "\n",
        "    def predict(self, x_encoder):  # 予測に使用\n",
        "        if self.is_gpu:\n",
        "            x_encoder = x_encoder.cuda()\n",
        "\n",
        "        batch_size = x_encoder.shape[0]\n",
        "        n_time = x_encoder.shape[1]\n",
        "        y_encoder, h = self.encoder(x_encoder)\n",
        "\n",
        "        y_decoder = torch.zeros(batch_size, n_time, dtype=torch.long)\n",
        "        if self.is_gpu:\n",
        "            y_decoder = y_decoder.cuda() \n",
        "\n",
        "        y = torch.ones(batch_size, 1, dtype=torch.long) * input_field.vocab.stoi[\"<sos>\"]\n",
        "        for t in range(0, n_time):\n",
        "            x = y  # 前の時刻の出力を入力に\n",
        "            if self.is_gpu:\n",
        "                x = x.cuda()\n",
        "            y, h= self.decoder(x, h, y_encoder)\n",
        "            y = y.argmax(2)\n",
        "            y_decoder[:, t:t+1] = y  \n",
        "        return y_decoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7arbUNhax7Y"
      },
      "source": [
        "## 評価用の関数\n",
        "実際に入力文に対して返答を生成し、モデルを評価するための関数を定義します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CteJ3NIpwQaF"
      },
      "source": [
        "def evaluate_model(model, iterator):\n",
        "    model.eval()  # 評価モード\n",
        "\n",
        "    batch = next(iter(iterator))\n",
        "    x = batch.inp_text\n",
        "    y = model.predict(x)\n",
        "    for i in range(x.size()[0]):\n",
        "        inp_text = \"\"\n",
        "        for j in range(x.size()[1]):\n",
        "            word = input_field.vocab.itos[x[i][j]]\n",
        "            if word==\"<pad>\":\n",
        "                break\n",
        "            inp_text += word\n",
        "\n",
        "        rep_text = \"\"\n",
        "        for j in range(y.size()[1]):\n",
        "            word = reply_field.vocab.itos[y[i][j]]\n",
        "            if word==\"<eos>\":\n",
        "                break\n",
        "            rep_text += word\n",
        "\n",
        "        print(\"input:\", inp_text)\n",
        "        print(\"reply:\", rep_text)\n",
        "        print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LlU7bHhC0Fj"
      },
      "source": [
        "## 学習\n",
        "DataLoaderを使ってミニバッチを取り出し、Seq2Seqのモデルを訓練します。  \n",
        "今回は、評価用データの誤差の減少が確認できなくなった時点で訓練を終了します（早期終了）。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fc0297QKC01y"
      },
      "source": [
        "from torch import optim\n",
        "\n",
        "is_gpu = True  # GPUを使用するかどうか\n",
        "n_h = 896\n",
        "n_vocab_inp = len(input_field.vocab.itos)\n",
        "n_vocab_rep = len(reply_field.vocab.itos)\n",
        "n_emb = 300\n",
        "n_out = n_vocab_rep\n",
        "early_stop_patience = 5  # 早期終了のタイミング（誤差の最小値が何回更新されなかったら終了か）\n",
        "num_layers = 1\n",
        "bidirectional = True\n",
        "dropout = 0.0\n",
        "clip = 100\n",
        "\n",
        "# Seq2Seqのモデルを構築\n",
        "encoder = Encoder(n_h, n_vocab_inp, n_emb, num_layers, bidirectional, dropout=dropout)\n",
        "decoder = Decoder(n_h, n_out, n_vocab_rep, n_emb, num_layers, dropout=dropout)\n",
        "seq2seq = Seq2Seq(encoder, decoder, is_gpu=is_gpu)\n",
        "\n",
        "# 誤差関数\n",
        "loss_fnc = nn.CrossEntropyLoss(ignore_index=reply_field.vocab.stoi[\"<pad>\"])\n",
        "\n",
        "# 最適化アルゴリズム\n",
        "optimizer_enc = optim.Adam(seq2seq.parameters(), lr=0.0001)\n",
        "optimizer_dec = optim.Adam(seq2seq.parameters(), lr=0.0005)\n",
        "\n",
        "# 損失のログ\n",
        "record_loss_train = []\n",
        "record_loss_test = []\n",
        "min_losss_test = 0.0\n",
        "\n",
        "# 学習\n",
        "for i in range(1000):\n",
        "    # 訓練モード\n",
        "    seq2seq.train()\n",
        "\n",
        "    loss_train = 0\n",
        "    for j, batch in enumerate(train_iterator):\n",
        "        inp, rep = batch.inp_text, batch.rep_text\n",
        "        x_enc = inp\n",
        "        x_dec = rep[:, :-1]\n",
        "        y_dec = seq2seq(x_enc, x_dec)\n",
        "\n",
        "        t_dec = rep[:, 1:]\n",
        "        t_dec = t_dec.cuda() if is_gpu else t_dec\n",
        "        loss = loss_fnc(\n",
        "            y_dec.view(-1, y_dec.size()[2]),\n",
        "            t_dec.view(-1)\n",
        "            )\n",
        "        loss_train += loss.item()\n",
        "        optimizer_enc.zero_grad()\n",
        "        optimizer_dec.zero_grad()\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
        "        nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
        "        optimizer_enc.step()\n",
        "        optimizer_dec.step()\n",
        "\n",
        "        if j%1000==0:\n",
        "            print(\"batch:\", str(j)+\"/\"+str(len(train_data)//batch_size+1), \"loss:\", loss.item())\n",
        "    loss_train /= j+1\n",
        "    record_loss_train.append(loss_train)\n",
        "\n",
        "    # 評価モード\n",
        "    seq2seq.eval()\n",
        "\n",
        "    loss_test = 0\n",
        "    for j, batch in enumerate(test_iterator):\n",
        "        inp, rep = batch.inp_text, batch.rep_text\n",
        "        x_enc = inp\n",
        "        x_dec = torch.ones(rep.size(), dtype=torch.long) * reply_field.vocab.stoi[\"<sos>\"]\n",
        "        x_dec[:, 1:] = rep[:, :-1]\n",
        "        y_dec = seq2seq(x_enc, x_dec)\n",
        "\n",
        "        t_dec = rep.cuda() if is_gpu else rep\n",
        "        loss = loss_fnc(\n",
        "            y_dec.view(-1, y_dec.size()[2]),\n",
        "            t_dec.view(-1)\n",
        "            )\n",
        "        loss_test += loss.item()\n",
        "    loss_test /= j+1\n",
        "    record_loss_test.append(loss_test)\n",
        "\n",
        "    if i%1 == 0:\n",
        "        print(\"Epoch:\", i, \"Loss_Train:\", loss_train, \"Loss_Test:\", loss_test)\n",
        "        print()\n",
        "\n",
        "    evaluate_model(seq2seq, test_iterator)\n",
        "\n",
        "    # ----- 早期終了 -----\n",
        "    latest_min = min(record_loss_test[-(early_stop_patience):])  # 直近の最小値\n",
        "    if len(record_loss_test) >= early_stop_patience:\n",
        "        if latest_min > min_loss_test:  # 直近で最小値が更新されていなければ\n",
        "            print(\"Early stopping!\")\n",
        "            break\n",
        "        min_loss_test = latest_min\n",
        "    else:\n",
        "        min_loss_test = latest_min"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJwwrWTw43rx"
      },
      "source": [
        "## 誤差の推移\n",
        "誤差の推移をグラフ表示します。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaJx4swE45XI"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(range(len(record_loss_train)), record_loss_train, label=\"Train\")\n",
        "plt.plot(range(len(record_loss_test)), record_loss_test, label=\"Test\")\n",
        "plt.legend()\n",
        "\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Error\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrRAJzwD4zpN"
      },
      "source": [
        "## モデルの保存\n",
        "訓練済みモデルのパラメータを保存します。    \n",
        "`state_dict()`によりモデルの各パラメータが取得できるので、これを保存します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pdy9nPckTDik"
      },
      "source": [
        "import torch\n",
        "\n",
        "# state_dict()の表示\n",
        "for key in seq2seq.state_dict():\n",
        "    print(key, \":\", seq2seq.state_dict()[key].size())\n",
        "print(seq2seq.state_dict()[\"encoder.gru.weight_ih_l0\"][0])  # 　パラメータの一部を表示\n",
        "\n",
        "# 保存\n",
        "torch.save(seq2seq.state_dict(), path+\"model_bot.pth\")  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stRWVWyGJwYN"
      },
      "source": [
        "## モデルの読み込み\n",
        "保存したパラメータを読み込み、モデルに設定します。  \n",
        "`torch.load()`で`map_location`にCPUを指定することで、GPUで訓練したモデルをCPUで使用することが可能になります。  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfHfzp_fBgHw"
      },
      "source": [
        "# 読み込み\n",
        "encoder_loaded = Encoder(n_h, n_vocab_inp, n_emb, num_layers, bidirectional, dropout=dropout)\n",
        "decoder_loaded = Decoder(n_h, n_out, n_vocab_rep, n_emb, num_layers, dropout=dropout)\n",
        "seq2seq_loaded = Seq2Seq(encoder_loaded, decoder_loaded, is_gpu=is_gpu)\n",
        "\n",
        "seq2seq_loaded.load_state_dict(torch.load(path+\"model_bot.pth\", map_location=torch.device(\"cpu\")))  #CPU対応\n",
        "seq2seq_loaded.eval()  # 評価モード\n",
        "\n",
        "# state_dict()の表示\n",
        "for key in seq2seq_loaded.state_dict():\n",
        "    print(key, \": \", seq2seq_loaded.state_dict()[key].size())\n",
        "print(seq2seq_loaded.state_dict()[\"encoder.gru.weight_ih_l0\"][0])  # 　パラメータの一部を表示"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8hAIcYLJnA1"
      },
      "source": [
        "モデルの各パラメータを保存し、読み込むことができました。"
      ]
    }
  ]
}